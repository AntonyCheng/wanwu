# 医疗文本脱敏mcp

这是一个专业的、高度可配置的医疗文本脱敏微服务，基于 `FastMCP` 框架构建。它创新性地结合了**正则表达式规则**和**大型语言模型 (LLM)** 的双重优势，旨在为医疗数据提供安全、可靠且智能的隐私保护解决方案。

## 核心理念：双模脱敏

该服务提供了两种核心的脱敏模式，以适应不同的应用场景：

1.  **静态脱敏 (Static Desensitization)**
    *   **用途**: 主要用于数据查询和前端展示。当需要向普通用户或低权限用户展示数据时，此模式可以有效隐藏敏感信息，但保留其存在痕迹。
    *   **典型方法**: **掩码 (Masking)**，例如将 "张三" 脱敏为 "张\*\*\"，将身份证号部分数字替换为 `*`。

2.  **动态脱敏 (Dynamic Desensitization)**
    *   **用途**: 主要用于数据导出、共享、分析或模型训练。此模式旨在生成与原始数据结构和类型相似的、逼真的假数据，以最大限度地保留数据的统计学特征和可用性。
    *   **典型方法**: **替换 (Replacement)** 和 **哈希 (Hashing)**，例如将 "张三" 替换为 "李四"，或将 "北京协和医院" 替换为 "XX人民医院"，同时确保在同一次处理中替换的一致性。

## 关键功能与技术亮点

1.  **混合检测引擎 (Hybrid Detection Engine)**
    *   **基础检测**: 内置了一套详尽的**正则表达式规则集**，能够快速、准确地识别包括姓名、身份证、电话、地址、各种医疗号码（住院号、病理号等）、医院名称和医生签名在内的多种确定性敏感字段。
    *   **LLM 智能增强**: 集成了大型语言模型（默认使用 DeepSeek API），用于检测正则表达式难以覆盖的、更具上下文依赖的模糊或非结构化敏感信息。当启用时，LLM 作为第二道防线，显著提高了检测的召回率和准确性。

2.  **LLM 一步式智能脱敏 (LLM-Powered Direct Desensitization)**
    *   **核心优势**: 提供 `llm_direct_desensitize` 工具，这是服务的**推荐使用方法**。它不依赖于“先检测后替换”的传统模式，而是将整个文本和脱敏指令直接发送给 LLM，由模型智能地理解上下文并直接生成完全脱敏后的文本。
    *   **效果**: 这种方法能更好地保留原始文本的格式和通顺性，处理复杂或嵌套的敏感信息时效果尤为出色。

3.  **灵活的脱敏策略 (Flexible Desensitization Strategies)**
    *   提供多种原子脱敏方法，包括**掩码 (Mask)**、**替换 (Replace)**、**哈希 (Hash)** 和 **移除 (Remove)**，用户可以为不同类型的敏感字段灵活配置不同的脱敏策略。

4.  **运行时配置与管理 (Runtime Configuration & Management)**
    *   **LLM 配置**: 用户可以通过 `configure_llm` 工具在服务运行时动态配置或更换 LLM 的 API Key、模型、API 端点等参数，无需重启服务。
    *   **规则管理**: 支持通过 API 获取默认规则 (`get_default_rules`) 或创建临时的自定义规则 (`create_custom_rule`)，提供了极高的灵活性。

5.  **高效的批量处理 (Efficient Batch Processing)**
    *   提供了 `batch_desensitize` 和 `batch_llm_desensitize` 工具，能够高效地并发处理大量文本，并支持将结果导出为 JSON、CSV 或 TXT 等多种格式。

6.  **健壮的架构设计 (Robust Architecture)**
    *   **智能降级**: 在 LLM 未配置或调用失败时，服务会自动降级到纯正则表达式模式，保证核心功能的可用性。
    *   **类型安全**: 全面使用 `Pydantic` 定义数据模型，确保了 API 接口的健壮性和易用性。
    *   **一致性保障**: 内置替换缓存机制，确保在同一次会话中，相同的敏感信息在动态脱敏时会被替换为相同的假数据（例如 "张三" 总是被替换为 "李四"）。该缓存也可以通过 `clear_replacement_cache` 工具手动清除。

## 配置环境变量（可选，用于LLM增强）

```bash
# DeepSeek 或其它大模型 API 配置
export OPENAI_API_KEY="sk-xxxxxxx"
```

### 启动MCP服务器

```bash
python medical_desensitization_mcp.py
```

服务器将在 `http://0.0.0.0:8008/mcp` 上启动。