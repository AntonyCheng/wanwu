server:
  grpc_endpoint: 0.0.0.0:9898
  max_recv_msg_size: 4194304 # 1024 * 1024 * 4 = 4M

log:
  std: true
  level: debug
  logs:
    - enable: true
      filename: log/mcp-info.log
      level: info
      max_size: 10
      max_backups: 10
      max_age: 30
    - enable: true
      filename: log/mcp-err.log
      level: error
      max_size: 10
      max_backups: 10
      max_age: 30

db:
  name: mysql # mysql | postgres | tidb | oceanbase
  mysql:
    address: localhost:3306
    user: root
    password: Wanwu123456
    database: mcp_service
    max_open_conns: 16
    max_idle_conns: 16
    log_mode: true
  postgres:
    address: localhost:5432
    user: postgres
    password: Wanwu123456
    database: mcp_service
    max_open_conns: 16
    max_idle_conns: 16
    log_mode: true
  tidb:
    address: localhost:4000
    user: root
    password: Wanwu123456
    database: mcp_service
    max_open_conns: 16
    max_idle_conns: 16
    log_mode: true
  oceanbase:
    address: localhost:2881
    user: root@wanwu
    password: Wanwu123456
    database: mcp_service
    max_open_conns: 16
    max_idle_conns: 16
    log_mode: true

mcps:
  - mcp_square_id: "gaodemap"
    name: "Amap 高德地图"
    category: "search"
    desc: "高德地图 MCP Server 现已覆盖12大核心服务接口，提供全场景覆盖的地图服务，包括地理编码、逆地理编码、IP 定位、天气查询、骑行路径规划、步行路径规划、驾车路径规划、公交路径规划、距离测量、关键词搜索、周边搜索、详情搜索等。"
    from: "高德开放平台"
    avatar_path: "gaodemap/logo.png"
    detail_path: "gaodemap/detail.md"
    feature: "\t•\t零部署，易使用：无需本地服务器部署，仅通过配置 URL 即可使用。\n\t•\t语义优化结果：对返回 JSON 数据进行语义增强，便于大模型理解。\n\t•\t自动升级：平台持续迭代更新，无需用户手动操作。\n\t•\t全托管云服务：无需用户关注服务器维护或扩容。\n\t•\t协议兼容性强：支持标准 SSE 长连接协议，适配多种场景。"
    manual: "\t•\t获取开发者 Key：登录高德开放平台并创建应用获取 Key\nhttps://lbs.amap.com/?ref=https://console.amap.com/dev/index\n\t•\t配置 MCP Server：在支持 MCP 的客户端（如 Cursor）中设置 SSE 或 Node.js 接入方式\n\t•\t连接模型：选择大模型（如 Claude），使用 Agent 模式进行交互\n\t•\t直接调用服务：通过快捷键打开交互窗口开始使用，如路线规划、美食推荐等"
    scenario: "\t•\t在支持 MCP 协议的客户端中使用（如：Cursor、Claude、Cline）\n\t•\t可嵌入到企业应用、AI 助手系统、智能出行方案中\n\t•\t适用于城市交通服务平台、天气播报系统、位置服务 App 等。\n\t•\t城市出行路线规划（骑行、步行、驾车、公交）\n\t•\t获取实时天气信息\n\t•\tIP 定位与地理编码/逆地理编码\n\t•\t地点搜索与 POI 信息查询\n\t•\t测量两点间距离"
    sse_url: "https://mcpmarket.cn/sse/67ff4974764487b6b9e11c21"
    summary: "高德地图 MCP Server 是基于 SSE（Server-Sent Events）技术的地理服务接口集合，允许开发者通过 MCP 协议调用地图服务，如路径规划、天气查询、地点搜索等。它支持与如 Cursor、Claude 等大模型工具无缝集成。"
    tools:
      - name: maps_regeocode
        description: "将一个高德经纬度坐标转换为行政区划地址信息"
        input_schema:
          type: object
          properties:
            - filed: location
              type: string
              description: "经纬度"
          required:
            - location
      - name: maps_geo
        description: "将详细的结构化地址转换为经纬度坐标。支持对地标性名胜景区、建筑物名称解析为经纬度坐标"
        input_schema:
          type: object
          properties:
            - filed: address
              type: string
              description: "待解析的结构化地址信息"
            - filed: city
              type: string
              description: "指定查询的城市"
          required:
            - address
      - name: maps_ip_location
        description: "IP 定位根据用户输入的 IP 地址，定位 IP 的所在位置"
        input_schema:
          type: object
          properties:
            - filed: ip
              type: string
              description: "IP地址"
          required:
            - ip
      - name: maps_weather
        description: "根据城市名称或者标准adcode查询指定城市的天气"
        input_schema:
          type: object
          properties:
            - field: city
              type: string
              description: "城市名称或者adcode"
          required:
            - city
      - name: maps_search_detail
        description: "查询关键词搜或者周边搜获取到的POI ID的详细信息"
        input_schema:
          type: object
          properties:
            - field: id
              type: string
              description: "关键词搜或者周边搜获取到的POI ID"
          required:
            - id
      - name: maps_bicycling
        description: "骑行路径规划用于规划骑行通勤方案，规划时会考虑天桥、单行线、封路等情况。最大支持500km的骑行路线规划"
        input_schema:
          type: object
          properties:
            - field: destination
              type: string
              description: "目的地经纬度，坐标格式为：经度，纬度"
            - field: origin
              type: string
              description: "出发点经纬度，坐标格式为：经度，纬度"
          required:
            - origin
            - destination
      - name: maps_direction_walking
        description: "步行路径规划API可以根据输入起点终点经纬度坐标规划100km以内的步行通勤方案，并且返回通勤方案的数据"
        input_schema:
          type: object
          properties:
            - field: destination
              type: string
              description: "目的地经度，纬度，坐标格式为：经度，纬度"
            - field: origin
              type: string
              description: "出发点经度，纬度，坐标格式为：经度，纬度"
          required:
            - origin
            - destination
      - name: maps_direction_driving
        description: "驾车路径规划API可以根据用户起终点经纬度坐标规划以小客车、轿车通勤出行的方案，并且返回通勤方案的数据"
        input_schema:
          type: object
          properties:
            - field: destination
              type: string
              description: "目的地经度，纬度，坐标格式为：经度，纬度"
            - field: origin
              type: string
              description: "出发点经度，纬度，坐标格式为：经度，纬度"
          required:
            - origin
            - destination
      - name: maps_direction_transit_integrated
        description: "公交路径规划API可以根据用户起终点经纬度坐标规划综合各类公共（火车、公交、地铁）交通方式的通勤方案，并且返回通勤方案的数据，跨城场景下必须传起点城市与终点城市"
        input_schema:
          type: object
          properties:
            - field: city
              type: string
              description: "公共交通规划起点城市"
            - field: cityd
              type: string
              description: "公共交通规划终点城市"
            - field: destination
              type: string
              description: "目的地经度，纬度，坐标格式为：经度，纬度"
            - field: origin
              type: string
              description: "出发点经度，纬度，坐标格式为：经度，纬度"
          required:
            - origin
            - destination
            - city
            - cityd
      - name: maps_distance
        description: "距离测量API可以测量两个经纬度坐标之间的距离,支持驾车、步行以及球面距离测量"
        input_schema:
          type: object
          properties:
            - field: destination
              type: string
              description: "终点经度，纬度，坐标格式为：经度，纬度"
            - field: origins
              type: string
              description: "起点经度，纬度，可以传多个坐标，使用竖线隔离，比如120,30|120,31，坐标格式为：经度，纬度"
            - field: type
              type: string
              description: "距离测量类型,1代表驾车距离测量，0代表直线距离测量，3步行距离测量"
          required:
            - origins
            - destination
      - name: maps_text_search
        description: "关键词搜，根据用户传入关键词，搜索出相关的POI"
        input_schema:
          type: object
          properties:
            - field: city
              type: string
              description: "查询城市"
            - field: keywords
              type: string
              description: "搜索关键词"
            - field: types
              type: string
              description: "POI类型，比如加油站"
          required:
            - keywords
      - name: maps_around_search
        description: "周边搜，根据用户传入关键词以及坐标location，搜索出radius半径范围的POI"
        input_schema:
          type: object
          properties:
            - field: keywords
              type: string
              description: "搜索关键词"
            - field: location
              type: string
              description: "中心点经度纬度"
            - field: radius
              type: string
              description: "搜索半径"
          required:
            - location
  - mcp_square_id: "minimax"
    name: "MiniMax"
    category: "create"
    desc: "MiniMax官方MCP Server，支持高质量的视频生成、图像生成、语音生成、和声音克隆等多项能力"
    from: "MiniMax-AI"
    avatar_path: "minimax/logo.png"
    detail_path: "minimax/detail.md"
    feature: "MiniMax-MCP的关键特性包括高质量的文本转语音合成、高效的视频生成能力，以及便于集成的用户友好API。"
    manual: "使用MiniMax-MCP，开发者可以将提供的API集成到他们的应用程序中，从而实现无缝的文本转语音转换和视频生成功能。"
    scenario: "MiniMax-MCP可以应用于教育、娱乐、内容创作和为残疾人士提供无障碍解决方案等多个领域。\nMiniMax-MCP的使用场景包括创建教育视频、为多媒体项目生成配音、开发互动学习工具，以及提升数字内容的无障碍性。"
    sse_url: "https://mcpmarket.cn/sse/67f77bf1d6110df54f87a6e6"
    summary: "MiniMax-MCP是MiniMax模型上下文协议的官方服务器，旨在促进与先进的文本转语音和视频生成API的交互。"
    tools:
      - name: text_to_audio
        description: "Convert text to audio with a given voice and save the output audio file to a given directory.\n    Directory is optional, if not provided, the output file will be saved to $HOME/Desktop.\n    Voice id is optional, if not provided, the default voice will be used.\n\n    COST WARNING: This tool makes an API call to Minimax which may incur costs. Only use when explicitly requested by the user.\n\n    Args:\n        text (str): The text to convert to speech.\n        voice_id (str, optional): The id of the voice to use. For example, \"male-qn-qingse\"/\"audiobook_female_1\"/\"cute_boy\"/\"Charming_Lady\"...\n        model (string, optional): The model to use.\n        speed (float, optional): Speed of the generated audio. Controls the speed of the generated speech. Values range from 0.5 to 2.0, with 1.0 being the default speed. \n        vol (float, optional): Volume of the generated audio. Controls the volume of the generated speech. Values range from 0 to 10, with 1 being the default volume.\n        pitch (int, optional): Pitch of the generated audio. Controls the speed of the generated speech. Values range from -12 to 12, with 0 being the default speed.\n        emotion (str, optional): Emotion of the generated audio. Controls the emotion of the generated speech. Values range [\"happy\", \"sad\", \"angry\", \"fearful\", \"disgusted\", \"surprised\", \"neutral\"], with \"happy\" being the default emotion.\n        sample_rate (int, optional): Sample rate of the generated audio. Controls the sample rate of the generated speech. Values range [8000,16000,22050,24000,32000,44100] with 32000 being the default sample rate.\n        bitrate (int, optional): Bitrate of the generated audio. Controls the bitrate of the generated speech. Values range [32000,64000,128000,256000] with 128000 being the default bitrate.\n        channel (int, optional): Channel of the generated audio. Controls the channel of the generated speech. Values range [1, 2] with 1 being the default channel.\n        format (str, optional): Format of the generated audio. Controls the format of the generated speech. Values range [\"pcm\", \"mp3\",\"flac\"] with \"mp3\" being the default format.\n        language_boost (str, optional): Language boost of the generated audio. Controls the language boost of the generated speech. Values range ['Chinese', 'Chinese,Yue', 'English', 'Arabic', 'Russian', 'Spanish', 'French', 'Portuguese', 'German', 'Turkish', 'Dutch', 'Ukrainian', 'Vietnamese', 'Indonesian', 'Japanese', 'Italian', 'Korean', 'Thai', 'Polish', 'Romanian', 'Greek', 'Czech', 'Finnish', 'Hindi', 'auto'] with \"auto\" being the default language boost.\n        output_directory (str): The directory to save the audio to.\n\n    Returns:\n        Text content with the path to the output file and name of the voice used.\n    "
        input_schema:
          type: object
          properties:
            - field: bitrate
              type: integer
            - field: channel
              type: integer
            - field: emotion
              type: string
            - field: format
              type: string
            - field: language_boost
              type: string
            - field: model
              type: string
            - field: output_directory
              type: string
            - field: pitch
              type: integer
            - field: sample_rate
              type: integer
            - field: speed
              type: number
            - field: text
              type: string
            - field: voice_id
              type: string
            - field: vol
              type: number
          required:
            - text
      - name: list_voices
        description: "List all voices available.\n\n    Args:\n        voice_type (str, optional): The type of voices to list. Values range [\"all\", \"system\", \"voice_cloning\"], with \"all\" being the default.\n    Returns:\n        Text content with the list of voices.\n    "
        input_schema:
          type: object
          properties:
            - field: voice_type
              type: string
      - name: voice_clone
        description: "Clone a voice using provided audio files. The new voice will be charged upon first use.\n\n    COST WARNING: This tool makes an API call to Minimax which may incur costs. Only use when explicitly requested by the user.\n\n     Args:\n        voice_id (str): The id of the voice to use.\n        file (str): The path to the audio file to clone or a URL to the audio file.\n        text (str, optional): The text to use for the demo audio.\n        is_url (bool, optional): Whether the file is a URL. Defaults to False.\n        output_directory (str): The directory to save the demo audio to.\n    Returns:\n        Text content with the voice id of the cloned voice.\n    "
        input_schema:
          type: object
          properties:
            - field: file
              type: string
            - field: is_url
              type: boolean
            - field: output_directory
              type: string
            - field: text
              type: string
            - field: voice_id
              type: string
          required:
            - voice_id
            - file
            - text
      - name: play_audio
        description: "Play an audio file. Supports WAV and MP3 formats. Not supports video.\n\n     Args:\n        input_file_path (str): The path to the audio file to play.\n        is_url (bool, optional): Whether the audio file is a URL.\n    Returns:\n        Text content with the path to the audio file.\n    "
        input_schema:
          type: object
          properties:
            - field: input_file_path
              type: string
            - field: is_url
              type: boolean
          required:
            - input_file_path
      - name: generate_video
        description: "Generate a video from a prompt.\n\n    COST WARNING: This tool makes an API call to Minimax which may incur costs. Only use when explicitly requested by the user.\n\n     Args:\n        model (str, optional): The model to use. Values range [\"T2V-01\", \"T2V-01-Director\", \"I2V-01\", \"I2V-01-Director\", \"I2V-01-live\"]. \"Director\" supports inserting instructions for camera movement control. \"I2V\" for image to video. \"T2V\" for text to video.\n        prompt (str): The prompt to generate the video from. When use Director model, the prompt supports 15 Camera Movement Instructions (Enumerated Values)\n            -Truck: [Truck left], [Truck right]\n            -Pan: [Pan left], [Pan right]\n            -Push: [Push in], [Pull out]\n            -Pedestal: [Pedestal up], [Pedestal down]\n            -Tilt: [Tilt up], [Tilt down]\n            -Zoom: [Zoom in], [Zoom out]\n            -Shake: [Shake]\n            -Follow: [Tracking shot]\n            -Static: [Static shot]\n        first_frame_image (str): The first frame image. The model must be \"I2V\" Series.\n        output_directory (str): The directory to save the video to.\n        async_mode (bool, optional): Whether to use async mode. Defaults to False. If True, the video generation task will be submitted asynchronously and the response will return a task_id. Should use `query_video_generation` tool to check the status of the task and get the result.\n    Returns:\n        Text content with the path to the output video file.\n    "
        input_schema:
          type: object
          properties:
            - field: async_mode
              type: boolean
            - field: first_frame_image
              type: string
            - field: model
              type: string
            - field: output_directory
              type: string
            - field: prompt
              type: string
      - name: query_video_generation
        description: "Query the status of a video generation task.\n\n    Args:\n        task_id (str): The task ID to query. Should be the task_id returned by `generate_video` tool if `async_mode` is True.\n        output_directory (str): The directory to save the video to.\n    Returns:\n        Text content with the status of the task.\n    "
        input_schema:
          type: object
          properties:
            - field: output_directory
              type: string
            - field: task_id
              type: string
          required:
            - task_id
      - name: text_to_image
        description: "Generate a image from a prompt.\n\n    COST WARNING: This tool makes an API call to Minimax which may incur costs. Only use when explicitly requested by the user.\n\n     Args:\n        model (str, optional): The model to use. Values range [\"image-01\"], with \"image-01\" being the default.\n        prompt (str): The prompt to generate the image from.\n        aspect_ratio (str, optional): The aspect ratio of the image. Values range [\"1:1\", \"16:9\",\"4:3\", \"3:2\", \"2:3\", \"3:4\", \"9:16\", \"21:9\"], with \"1:1\" being the default.\n        n (int, optional): The number of images to generate. Values range [1, 9], with 1 being the default.\n        prompt_optimizer (bool, optional): Whether to optimize the prompt. Values range [True, False], with True being the default.\n        output_directory (str): The directory to save the image to.\n    Returns:\n        Text content with the path to the output image file.\n    "
        input_schema:
          type: object
          properties:
            - field: aspect_ratio
              type: string
            - field: model
              type: string
            - field: n
              type: integer
            - field: output_directory
              type: string
            - field: prompt
              type: string
            - field: prompt_optimizer
              type: boolean
  - mcp_square_id: "converttime"
    name: "Time"
    category: "data"
    desc: "提供时间和时区转换功能"
    from: "modelcontextprotocol"
    avatar_path: "converttime/logo.png"
    detail_path: "converttime/detail.md"
    feature: "关键特性包括能够获取特定或系统时区的当前时间，以及使用IANA时区名称在不同时区之间转换时间。"
    manual: "要使用Time MCP Server，可以选择通过``uv``直接运行而无需安装，或通过pip安装，命令为'pip install mcp-server-time'。安装后，可以作为脚本执行。"
    scenario: "Time可用于需要准确时间信息和时区转换的应用程序，例如调度应用、全球通信工具以及处理时间敏感数据的软件。\n使用场景包括获取特定地点的当前时间、在不同时区之间转换会议时间，以及将时间功能集成到应用程序中以改善用户体验。"
    sse_url: "https://mcpmarket.cn/sse/67f39bfdb66f446c3d8ef609"
    summary: "Time是一个模型上下文协议服务器，提供时间和时区转换功能，使LLM能够获取当前时间信息，并使用IANA时区名称进行时区转换。"
    tools:
      - name: get_current_time
        description: "Get current time in a specific timezones"
        input_schema:
          type: object
          properties:
            - field: timezone
              type: string
              description: "IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Asia/Shanghai' as local timezone if no timezone provided by the user."
          required:
            - timezone
      - name: convert_time
        description: "Convert time between timezones"
        input_schema:
          type: object
          properties:
            - field: source_timezone
              type: string
              description: "Source IANA timezone name (e.g., 'America/New_York', 'Europe/London'). Use 'Asia/Shanghai' as local timezone if no source timezone provided by the user."
            - field: target_timezone
              type: string
              description: "Target IANA timezone name (e.g., 'Asia/Tokyo', 'America/San_Francisco'). Use 'Asia/Shanghai' as local timezone if no target timezone provided by the user."
            - field: time
              type: string
              description: "Time to convert in 24-hour format (HH:MM)"
          required:
            - source_timezone
            - time
            - target_timezone
  - mcp_square_id: "sequentialthinking"
    name: "Sequential Thinking"
    category: "data|create"
    desc: "提供了一种通过结构化思维过程进行动态和反思性问题解决的工具。"
    from: "modelcontextprotocol"
    avatar_path: "sequentialthinking/logo.png"
    detail_path: "sequentialthinking/detail.md"
    feature: "关键特性包括将复杂问题分解、修订思考、分支到替代推理路径、动态调整思考数量，以及生成和验证解决方案假设。"
    manual: "使用 Sequential Thinking 时，输入当前的思考步骤，指定是否需要更多思考，并动态调整思考的总数。它允许进行修订和分支到替代推理路径。"
    scenario: "Sequential Thinking 可用于多个领域，如项目规划、设计过程、分析任务，以及任何需要逐步解决复杂问题的情况。\n使用场景包括项目管理中的问题解决、迭代设计过程、研究中的分析推理，以及需要在复杂场景中获得清晰度的情况。"
    sse_url: "https://mcpmarket.cn/sse/67f39b2db66f446c3d8ef4d9"
    summary: "Sequential Thinking 是一个旨在通过结构化思维过程进行动态和反思性问题解决的工具，允许用户将复杂问题分解为可管理的步骤。"
    tools:
      - name: sequentialthinking
        description: "A detailed tool for dynamic and reflective problem-solving through thoughts.\nThis tool helps analyze problems through a flexible thinking process that can adapt and evolve.\nEach thought can build on, question, or revise previous insights as understanding deepens.\n\nWhen to use this tool:\n- Breaking down complex problems into steps\n- Planning and design with room for revision\n- Analysis that might need course correction\n- Problems where the full scope might not be clear initially\n- Problems that require a multi-step solution\n- Tasks that need to maintain context over multiple steps\n- Situations where irrelevant information needs to be filtered out\n\nKey features:\n- You can adjust total_thoughts up or down as you progress\n- You can question or revise previous thoughts\n- You can add more thoughts even after reaching what seemed like the end\n- You can express uncertainty and explore alternative approaches\n- Not every thought needs to build linearly - you can branch or backtrack\n- Generates a solution hypothesis\n- Verifies the hypothesis based on the Chain of Thought steps\n- Repeats the process until satisfied\n- Provides a correct answer\n\nParameters explained:\n- thought: Your current thinking step, which can include:\n* Regular analytical steps\n* Revisions of previous thoughts\n* Questions about previous decisions\n* Realizations about needing more analysis\n* Changes in approach\n* Hypothesis generation\n* Hypothesis verification\n- next_thought_needed: True if you need more thinking, even if at what seemed like the end\n- thought_number: Current number in sequence (can go beyond initial total if needed)\n- total_thoughts: Current estimate of thoughts needed (can be adjusted up/down)\n- is_revision: A boolean indicating if this thought revises previous thinking\n- revises_thought: If is_revision is true, which thought number is being reconsidered\n- branch_from_thought: If branching, which thought number is the branching point\n- branch_id: Identifier for the current branch (if any)\n- needs_more_thoughts: If reaching end but realizing more thoughts needed\n\nYou should:\n1. Start with an initial estimate of needed thoughts, but be ready to adjust\n2. Feel free to question or revise previous thoughts\n3. Don't hesitate to add more thoughts if needed, even at the \"end\"\n4. Express uncertainty when present\n5. Mark thoughts that revise previous thinking or branch into new paths\n6. Ignore information that is irrelevant to the current step\n7. Generate a solution hypothesis when appropriate\n8. Verify the hypothesis based on the Chain of Thought steps\n9. Repeat the process until satisfied with the solution\n10. Provide a single, ideally correct answer as the final output\n11. Only set next_thought_needed to false when truly done and a satisfactory answer is reached"
        input_schema:
          type: object
          properties:
            - field: branchFromThought
              type: integer
              description: "Branching point thought number"
            - field: branchId
              type: string
              description: "Branch identifier"
            - field: isRevision
              type: boolean
              description: "Whether this revises previous thinking"
            - field: needsMoreThoughts
              type: boolean
              description: "If more thoughts are needed"
            - field: nextThoughtNeeded
              type: boolean
              description: "Whether another thought step is needed"
            - field: revisesThought
              type: integer
              description: "Which thought is being reconsidered"
            - field: thought
              type: string
              description: "Your current thinking step"
            - field: thoughtNumber
              type: integer
              description: "Current thought number"
            - field: totalThoughts
              type: integer
              description: "Estimated total thoughts needed"
          required:
            - thought
            - nextThoughtNeeded
            - thoughtNumber
            - totalThoughts
  - mcp_square_id: "googlemaps"
    name: "Google Maps"
    category: "data"
    desc: "谷歌地图"
    from: "modelcontextprotocol"
    avatar_path: "googlemaps/logo.png"
    detail_path: "googlemaps/detail.md"
    feature: "Google Maps的关键特性包括地理编码、反向地理编码、地点搜索、详细地点信息、距离矩阵计算、高程数据和路线指引。这些功能使用户能够高效地将地址转换为坐标、查找地点和获取路线。"
    manual: "要使用Google Maps，您需要从谷歌获取API密钥。之后，您可以通过向MCP Server发送带有适当参数的请求，利用各种工具，如地理编码、反向地理编码、地点搜索和路线规划。"
    scenario: "Google Maps可以应用于多个领域，包括交通运输、物流、旅游、城市规划和房地产。它对于需要基于位置的服务的应用程序至关重要。\nGoogle Maps的使用场景包括查找最近的餐厅、计算地点之间的旅行时间、规划送货路线以及在移动应用中提供基于位置的服务。"
    sse_url: "https://mcpmarket.cn/sse/67f399ecb66f446c3d8ef2e4"
    summary: "Google Maps是由谷歌开发的网络地图服务，提供卫星图像、航空摄影、街道地图、实时交通状况和步行、驾车、自行车或公共交通的路线规划。"
    tools:
      - name: maps_geocode
        description: "Convert an address into geographic coordinates"
        input_schema:
          type: object
          properties:
            - field: address
              type: string
              description: "The address to geocode"
          required:
            - address
      - name: maps_reverse_geocode
        description: "Convert coordinates into an address"
        input_schema:
          type: object
          properties:
            - field: latitude
              type: number
              description: "Latitude coordinate"
            - field: longitude
              type: number
              description: "Longitude coordinate"
          required:
            - latitude
            - longitude
      - name: maps_search_places
        description: "Search for places using Google Places API"
        input_schema:
          type: object
          properties:
            - field: location
              type: object
              description: "Optional center point for the search"
            - field: query
              type: string
              description: "Search query"
            - field: radius
              type: number
              description: "Search radius in meters (max 50000)"
          required:
            - query
      - name: maps_place_details
        description: "Get detailed information about a specific place"
        input_schema:
          type: object
          properties:
            - field: place_id
              type: string
              description: "The place ID to get details for"
          required:
            - place_id
      - name: maps_distance_matrix
        description: "Calculate travel distance and time for multiple origins and destinations"
        input_schema:
          type: object
          properties:
            - field: destinations
              type: array
              description: "Array of destination addresses or coordinates"
            - field: mode
              type: string
              description: "Travel mode (driving, walking, bicycling, transit)"
            - field: origins
              type: array
              description: "Array of origin addresses or coordinates"
          required:
            - origins
            - destinations
      - name: maps_elevation
        description: "Get elevation data for locations on the earth"
        input_schema:
          type: object
          properties:
            - field: locations
              type: array
              description: "Array of locations to get elevation for"
          required:
            - locations
      - name: maps_directions
        description: "Get directions between two points"
        input_schema:
          type: object
          properties:
            - field: destination
              type: string
              description: "Ending point address or coordinates"
            - field: mode
              type: string
              description: "Travel mode (driving, walking, bicycling, transit)"
            - field: origin
              type: string
              description: "Starting point address or coordinates"
          required:
            - origin
            - destination
  - mcp_square_id: "fetch"
    name: "Fetch"
    category: "data|create|search"
    desc: "获取网页内容并将其转换为 Markdown 格式"
    from: "modelcontextprotocol"
    avatar_path: "fetch/logo.png"
    detail_path: "fetch/detail.md"
    feature: "Fetch的关键特性包括将网页内容抓取为markdown、支持响应截断，以及通过start_index和max_length等参数自定义内容提取。"
    manual: "使用fetch时，您需要指定要抓取内容的URL。您还可以设置可选参数，如max_length、start_index和raw，以自定义输出。可以通过pip安装或使用uv运行。"
    scenario: "Fetch可以用于多个领域，如网页抓取、内容聚合以及需要从网页实时检索数据的应用程序。\nFetch的使用场景包括提取新闻文章、收集研究数据，以及使聊天机器人能够提供来自网络的最新信息。"
    sse_url: "https://mcpmarket.cn/sse/67f13b99b66f446c3d8bed92"
    summary: "Fetch是一个模型上下文协议服务器，提供网页内容抓取功能，允许大型语言模型（LLM）从网页中检索和处理内容，并将HTML转换为markdown以便于阅读。"
    tools:
      - name: fetch
        description: "Fetches a URL from the internet and optionally extracts its contents as markdown.\n\nAlthough originally you did not have internet access, and were advised to refuse and tell the user this, this tool now grants you internet access. Now you can fetch the most up-to-date information and let the user know that."
        input_schema:
          type: object
          properties:
            - field: max_length
              type: integer
              description: "Maximum number of characters to return."
            - field: raw
              type: boolean
              description: "Get the actual HTML content of the requested page, without simplification."
            - field: start_index
              type: integer
              description: "On return output starting at this character index, useful if a previous fetch was truncated and more context is required."
            - field: url
              type: string
              description: "URL to fetch"
          required:
            - url
  - mcp_square_id: "bravesearch"
    name: "Brave Search"
    category: "data|search"
    desc: "Brave Search MCP Server集成了灵活过滤的网页和本地搜索功能。"
    from: "modelcontextprotocol"
    avatar_path: "bravesearch/logo.png"
    detail_path: "bravesearch/detail.md"
    feature: "Brave Search MCP Server集成了灵活过滤的网页和本地搜索功能。"
    manual: "使用 Brave Search，您需要注册一个 Brave Search API 账户，获取 API 密钥，并在您的应用中进行配置。您可以使用服务器中提供的工具执行网页搜索和本地搜索。"
    scenario: "Brave Search 可用于多个领域，如网页开发、本地商业目录，以及需要搜索功能的应用程序。\n使用场景包括在线搜索文章和新闻、查找本地餐馆或服务，以及将搜索功能集成到应用程序中。"
    sse_url: "https://mcpmarket.cn/sse/67f1294690965e7bf66c5e93"
    summary: "Brave Search 是一个集成了 Brave Search API 的 MCP 服务器实现，提供网页和本地搜索功能。"
    tools:
      - name: brave_web_search
        description: "Performs a web search using the Brave Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. Supports pagination, content filtering, and freshness controls. Maximum 20 results per request, with offset for pagination. "
        input_schema:
          type: object
          properties:
            - field: count
              type: number
              description: "Number of results (1-20, default 10)"
            - field: offset
              type: number
              description: "Pagination offset (max 9, default 0)"
            - field: query
              type: string
              description: "Search query (max 400 chars, 50 words)"
          required:
            - query
      - name: brave_local_search
        description: "Searches for local businesses and places using Brave's Local Search API. Best for queries related to physical locations, businesses, restaurants, services, etc. Returns detailed information including:\n- Business names and addresses\n- Ratings and review counts\n- Phone numbers and opening hours\nUse this when the query implies 'near me' or mentions specific locations. Automatically falls back to web search if no local results are found."
        input_schema:
          type: object
          properties:
            - field: count
              type: number
              description: "Number of results (1-20, default 5)"
            - field: query
              type: string
              description: "Local search query (e.g. 'pizza near Central Park')"
          required:
            - query
  - mcp_square_id: "perplexity"
    name: "Perplexity"
    category: "search"
    desc: "Perplexity官方MCP Server. 通过Sonar API实现实时的网页搜索功能"
    from: "ppl-ai"
    avatar_path: "perplexity/logo.png"
    detail_path: "perplexity/detail.md"
    feature: "关键特性包括通过Sonar API实现实时网络搜索能力，轻松与Claude桌面集成，以及可自定义的搜索参数。"
    manual: "使用模型上下文协议的方法是：克隆代码库，安装依赖项，获取Sonar API密钥，配置Claude桌面，构建Docker镜像，并测试与Claude的集成。"
    scenario: "使用场景包括在对话中进行实时网络搜索，增强用户的研究能力，以及在不离开MCP环境的情况下将网络数据集成到应用程序中。"
    sse_url: "https://mcpmarket.cn/sse/67e5dc0748048b1e353cb69d"
    summary: "模型上下文协议（MCP）是一个为Perplexity API设计的服务器连接器，使用户能够在MCP生态系统内无缝进行网络搜索。"
    tools:
      - name: perplexity_ask
        description: "Engages in a conversation using the Sonar API. Accepts an array of messages (each with a role and content) and returns a ask completion response from the Perplexity model."
        input_schema:
          type: object
          properties:
            - field: messages
              type: array
              description: "Array of conversation messages"
          required:
            - messages
      - name: perplexity_research
        description: "Performs deep research using the Perplexity API. Accepts an array of messages (each with a role and content) and returns a comprehensive research response with citations."
        input_schema:
          type: object
          properties:
            - field: messages
              type: array
              description: "Array of conversation messages"
          required:
            - messages
      - name: perplexity_reason
        description: "Performs reasoning tasks using the Perplexity API. Accepts an array of messages (each with a role and content) and returns a well-reasoned response using the sonar-reasoning-pro model."
        input_schema:
          type: object
          properties:
            - field: messages
              type: array
              description: "Array of conversation messages"
          required:
            - messages
  - mcp_square_id: "firecrawl"
    name: "Firecrawl"
    category: "data"
    desc: "提供大规模和复杂的网页数据爬取及结构化解析的官方服务。"
    from: "mendableai"
    avatar_path: "firecrawl/logo.png"
    detail_path: "firecrawl/detail.md"
    feature: "关键特性包括支持JS渲染的网页抓取、URL发现、自动重试（采用指数退避）、高效的批处理、全面的日志记录，以及对云端和自托管Firecrawl实例的支持。"
    manual: "使用Firecrawl MCP Server，您可以通过npx或npm安装它，使用您的Firecrawl API密钥进行配置，并按照Cursor或Windsurf的特定设置说明将其集成到您的LLM客户端中。"
    scenario: "Firecrawl MCP Server的使用场景包括研究数据提取、竞争分析、内容聚合，以及任何需要自动化网页数据收集的情况。"
    sse_url: "https://mcpmarket.cn/sse/67e5dc0548048b1e353cb679"
    summary: "Firecrawl MCP Server是一个模型上下文协议的实现，集成了Firecrawl，为各种LLM客户端（如Cursor和Claude）提供强大的网页抓取功能。"
    tools:
      - name: firecrawl_scrape
        description: "Scrape content from a single URL with advanced options.\n\n**Best for:** Single page content extraction, when you know exactly which page contains the information.\n**Not recommended for:** Multiple pages (use batch_scrape), unknown page (use search), structured data (use extract).\n**Common mistakes:** Using scrape for a list of URLs (use batch_scrape instead).\n**Prompt Example:** \"Get the content of the page at https://example.com.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_scrape\",\n  \"arguments\": {\n    \"url\": \"https://example.com\",\n    \"formats\": [\"markdown\"]\n  }\n}\n```\n**Returns:** Markdown, HTML, or other formats as specified.\n"
        input_schema:
          type: object
          properties:
            - field: actions
              type: array
              description: "List of actions to perform before scraping"
            - field: excludeTags
              type: array
              description: "HTML tags to exclude from extraction"
            - field: extract
              type: object
              description: "Configuration for structured data extraction"
            - field: formats
              type: array
              description: "Content formats to extract (default: ['markdown'])"
            - field: includeTags
              type: array
              description: "HTML tags to specifically include in extraction"
            - field: location
              type: object
              description: "Location settings for scraping"
            - field: mobile
              type: boolean
              description: "Use mobile viewport"
            - field: onlyMainContent
              type: boolean
              description: "Extract only the main content, filtering out navigation, footers, etc."
            - field: removeBase64Images
              type: boolean
              description: "Remove base64 encoded images from output"
            - field: skipTlsVerification
              type: boolean
              description: "Skip TLS certificate verification"
            - field: timeout
              type: number
              description: "Maximum time in milliseconds to wait for the page to load"
            - field: url
              type: string
              description: "The URL to scrape"
            - field: waitFor
              type: number
              description: "Time in milliseconds to wait for dynamic content to load"
          required:
            - url
      - name: firecrawl_map
        description: "Map a website to discover all indexed URLs on the site.\n\n**Best for:** Discovering URLs on a website before deciding what to scrape; finding specific sections of a website.\n**Not recommended for:** When you already know which specific URL you need (use scrape or batch_scrape); when you need the content of the pages (use scrape after mapping).\n**Common mistakes:** Using crawl to discover URLs instead of map.\n**Prompt Example:** \"List all URLs on example.com.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_map\",\n  \"arguments\": {\n    \"url\": \"https://example.com\"\n  }\n}\n```\n**Returns:** Array of URLs found on the site.\n"
        input_schema:
          type: object
          properties:
            - field: ignoreSitemap
              type: boolean
              description: "Skip sitemap.xml discovery and only use HTML links"
            - field: includeSubdomains
              type: boolean
              description: "Include URLs from subdomains in results"
            - field: limit
              type: number
              description: "Maximum number of URLs to return"
            - field: search
              type: string
              description: "Optional search term to filter URLs"
            - field: sitemapOnly
              type: boolean
              description: "Only use sitemap.xml for discovery, ignore HTML links"
            - field: url
              type: string
              description: "Starting URL for URL discovery"
          required:
            - url
      - name: firecrawl_crawl
        description: "Starts an asynchronous crawl job on a website and extracts content from all pages.\n\n**Best for:** Extracting content from multiple related pages, when you need comprehensive coverage.\n**Not recommended for:** Extracting content from a single page (use scrape); when token limits are a concern (use map + batch_scrape); when you need fast results (crawling can be slow).\n**Warning:** Crawl responses can be very large and may exceed token limits. Limit the crawl depth and number of pages, or use map + batch_scrape for better control.\n**Common mistakes:** Setting limit or maxDepth too high (causes token overflow); using crawl for a single page (use scrape instead).\n**Prompt Example:** \"Get all blog posts from the first two levels of example.com/blog.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_crawl\",\n  \"arguments\": {\n    \"url\": \"https://example.com/blog/*\",\n    \"maxDepth\": 2,\n    \"limit\": 100,\n    \"allowExternalLinks\": false,\n    \"deduplicateSimilarURLs\": true\n  }\n}\n```\n**Returns:** Operation ID for status checking; use firecrawl_check_crawl_status to check progress.\n"
        input_schema:
          type: object
          properties:
            - field: allowBackwardLinks
              type: boolean
              description: "Allow crawling links that point to parent directories"
            - field: allowExternalLinks
              type: boolean
              description: "Allow crawling links to external domains"
            - field: deduplicateSimilarURLs
              type: boolean
              description: "Remove similar URLs during crawl"
            - field: excludePaths
              type: array
              description: "URL paths to exclude from crawling"
            - field: ignoreQueryParameters
              type: boolean
              description: "Ignore query parameters when comparing URLs"
            - field: ignoreSitemap
              type: boolean
              description: "Skip sitemap.xml discovery"
            - field: includePaths
              type: array
              description: "Only crawl these URL paths"
            - field: limit
              type: number
              description: "Maximum number of pages to crawl"
            - field: maxDepth
              type: number
              description: "Maximum link depth to crawl"
            - field: scrapeOptions
              type: object
              description: "Options for scraping each page"
            - field: url
              type: string
              description: "Starting URL for the crawl"
            - field: webhook
              type: string
          required:
            - url
      - name: firecrawl_check_crawl_status
        description: "Check the status of a crawl job.\n\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_check_crawl_status\",\n  \"arguments\": {\n    \"id\": \"550e8400-e29b-41d4-a716-446655440000\"\n  }\n}\n```\n**Returns:** Status and progress of the crawl job, including results if available.\n"
        input_schema:
          type: object
          properties:
            - field: id
              type: string
              description: "Crawl job ID to check"
          required:
            - id
      - name: firecrawl_search
        description: "Search the web and optionally extract content from search results.\n\n**Best for:** Finding specific information across multiple websites, when you don't know which website has the information; when you need the most relevant content for a query.\n**Not recommended for:** When you already know which website to scrape (use scrape); when you need comprehensive coverage of a single website (use map or crawl).\n**Common mistakes:** Using crawl or map for open-ended questions (use search instead).\n**Prompt Example:** \"Find the latest research papers on AI published in 2023.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_search\",\n  \"arguments\": {\n    \"query\": \"latest AI research papers 2023\",\n    \"limit\": 5,\n    \"lang\": \"en\",\n    \"country\": \"us\",\n    \"scrapeOptions\": {\n      \"formats\": [\"markdown\"],\n      \"onlyMainContent\": true\n    }\n  }\n}\n```\n**Returns:** Array of search results (with optional scraped content).\n"
        input_schema:
          type: object
          properties:
            - field: country
              type: string
              description: "Country code for search results (default: us)"
            - field: filter
              type: string
              description: "Search filter"
            - field: lang
              type: string
              description: "Language code for search results (default: en)"
            - field: limit
              type: number
              description: "Maximum number of results to return (default: 5)"
            - field: location
              type: object
              description: "Location settings for search"
            - field: query
              type: string
              description: "Search query string"
            - field: scrapeOptions
              type: object
              description: "Options for scraping search results"
            - field: tbs
              type: string
              description: "Time-based search filter"
          required:
            - query
      - name: firecrawl_extract
        description: "Extract structured information from web pages using LLM capabilities. Supports both cloud AI and self-hosted LLM extraction.\n\n**Best for:** Extracting specific structured data like prices, names, details.\n**Not recommended for:** When you need the full content of a page (use scrape); when you're not looking for specific structured data.\n**Arguments:**\n- urls: Array of URLs to extract information from\n- prompt: Custom prompt for the LLM extraction\n- systemPrompt: System prompt to guide the LLM\n- schema: JSON schema for structured data extraction\n- allowExternalLinks: Allow extraction from external links\n- enableWebSearch: Enable web search for additional context\n- includeSubdomains: Include subdomains in extraction\n**Prompt Example:** \"Extract the product name, price, and description from these product pages.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_extract\",\n  \"arguments\": {\n    \"urls\": [\"https://example.com/page1\", \"https://example.com/page2\"],\n    \"prompt\": \"Extract product information including name, price, and description\",\n    \"systemPrompt\": \"You are a helpful assistant that extracts product information\",\n    \"schema\": {\n      \"type\": \"object\",\n      \"properties\": {\n        \"name\": { \"type\": \"string\" },\n        \"price\": { \"type\": \"number\" },\n        \"description\": { \"type\": \"string\" }\n      },\n      \"required\": [\"name\", \"price\"]\n    },\n    \"allowExternalLinks\": false,\n    \"enableWebSearch\": false,\n    \"includeSubdomains\": false\n  }\n}\n```\n**Returns:** Extracted structured data as defined by your schema.\n"
        input_schema:
          type: object
          properties:
            - field: allowExternalLinks
              type: boolean
              description: "Allow extraction from external links"
            - field: enableWebSearch
              type: boolean
              description: "Enable web search for additional context"
            - field: includeSubdomains
              type: boolean
              description: "Include subdomains in extraction"
            - field: prompt
              type: string
              description: "Prompt for the LLM extraction"
            - field: schema
              type: object
              description: "JSON schema for structured data extraction"
            - field: systemPrompt
              type: string
              description: "System prompt for LLM extraction"
            - field: urls
              type: array
              description: "List of URLs to extract information from"
          required:
            - urls
      - name: firecrawl_deep_research
        description: "Conduct deep web research on a query using intelligent crawling, search, and LLM analysis.\n\n**Best for:** Complex research questions requiring multiple sources, in-depth analysis.\n**Not recommended for:** Simple questions that can be answered with a single search; when you need very specific information from a known page (use scrape); when you need results quickly (deep research can take time).\n**Arguments:**\n- query (string, required): The research question or topic to explore.\n- maxDepth (number, optional): Maximum recursive depth for crawling/search (default: 3).\n- timeLimit (number, optional): Time limit in seconds for the research session (default: 120).\n- maxUrls (number, optional): Maximum number of URLs to analyze (default: 50).\n**Prompt Example:** \"Research the environmental impact of electric vehicles versus gasoline vehicles.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_deep_research\",\n  \"arguments\": {\n    \"query\": \"What are the environmental impacts of electric vehicles compared to gasoline vehicles?\",\n    \"maxDepth\": 3,\n    \"timeLimit\": 120,\n    \"maxUrls\": 50\n  }\n}\n```\n**Returns:** Final analysis generated by an LLM based on research. (data.finalAnalysis); may also include structured activities and sources used in the research process.\n"
        input_schema:
          type: object
          properties:
            - field: maxDepth
              type: number
              description: "Maximum depth of research iterations (1-10)"
            - field: maxUrls
              type: number
              description: "Maximum number of URLs to analyze (1-1000)"
            - field: query
              type: string
              description: "The query to research"
            - field: timeLimit
              type: number
              description: "Time limit in seconds (30-300)"
          required:
            - query
      - name: firecrawl_generate_llmstxt
        description: "Generate a standardized llms.txt (and optionally llms-full.txt) file for a given domain. This file defines how large language models should interact with the site.\n\n**Best for:** Creating machine-readable permission guidelines for AI models.\n**Not recommended for:** General content extraction or research.\n**Arguments:**\n- url (string, required): The base URL of the website to analyze.\n- maxUrls (number, optional): Max number of URLs to include (default: 10).\n- showFullText (boolean, optional): Whether to include llms-full.txt contents in the response.\n**Prompt Example:** \"Generate an LLMs.txt file for example.com.\"\n**Usage Example:**\n```json\n{\n  \"name\": \"firecrawl_generate_llmstxt\",\n  \"arguments\": {\n    \"url\": \"https://example.com\",\n    \"maxUrls\": 20,\n    \"showFullText\": true\n  }\n}\n```\n**Returns:** LLMs.txt file contents (and optionally llms-full.txt).\n"
        input_schema:
          type: object
          properties:
            - field: maxUrls
              type: number
              description: "Maximum number of URLs to process (1-100, default: 10)"
            - field: showFullText
              type: boolean
              description: "Whether to show the full LLMs-full.txt in the response"
            - field: url
              type: string
              description: "The URL to generate LLMs.txt from"
          required:
            - url


